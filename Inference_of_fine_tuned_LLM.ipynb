{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "from tokenizers import (decoders, models, normalizers, pre_tokenizers, processors, trainers, Tokenizer)\n",
        "from transformers import GPT2Tokenizer, GPT2TokenizerFast, GPT2Model, GPT2LMHeadModel\n",
        "from transformers import TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
        "from huggingface_hub import login\n",
        "import logging\n",
        "import time\n",
        "from datasets import Dataset, DatasetDict, load_from_disk\n",
        "import os\n",
        "import torch"
      ],
      "metadata": {
        "id": "xCUvRI7dCo5N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "5ca3c342-080a-4626-dd0d-7cf8eca87598"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sC99-OVUtiy",
        "outputId": "798fdf82-9d2e-4d05-89ab-50f19160ad25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "# Hugging Face Token\n",
        "hf_token='XXXX'\n",
        "login(token=hf_token)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDqdsVVFVTFR",
        "outputId": "2cd6ccb6-d4b8-4be9-d844-3168d274ef0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecAGN-YDX6Ez",
        "outputId": "a4ad86d7-1d65-4a7b-d86d-9fdbe3c7a903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text: Однажды она решила\n",
            "Completed Text: Однажды она решила отправиться в город на поиски своего друга и помощника, который предлагает ему вернуться обратно. Но на этот раз ей удаётся уйти из города и забрать его с собой, чтобы спасти её. Тогда Стиву приходится поговорить со своей подругой Розиной (Нью-Йорк), но она понимает, что не может проявлять себя как мистер Мелвин. Кристин останавливается и говорит, что это просто та же история о том, кто живет. Она знакомит девушку с молодого Стива, которая начинает с нейтвы, поскольку они делают своих детей. После того жесто лететь он попадает за то, когда она уже давит их же самую, а потом. Тем, потому что они пытаются другому, если убивают вместе с помощью ещё сильнее, а затем будут выгляд, так называемые.   Дже. Когда она любит себя любовница сделала свою дочь, пока он хотела у неё ещё ранься, что она сама. Ната.  вшуюся. В то есть только тогда ещё\n"
          ]
        }
      ],
      "source": [
        "# Load the fine-tuned GPT-2 model for inference\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(\"/content/drive/MyDrive/Study/extended_tokenizer_gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "finetuned_model = GPT2LMHeadModel.from_pretrained(\"/content/drive/MyDrive/Study/rus_gpt2_2_epoch\")\n",
        "\n",
        "finetuned_model.eval()\n",
        "\n",
        "# Input text for completion\n",
        "input_text = \"Однажды она решила\"\n",
        "\n",
        "# Tokenize the input text\n",
        "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "\n",
        "max_length = 250\n",
        "# # Generate text completions\n",
        "# output_text = finetuned_model.generate(input_ids, max_length=max_length)[0]\n",
        "\n",
        "output_text = finetuned_model.generate(\n",
        "    input_ids,\n",
        "    max_length=max_length,\n",
        "    temperature=0.8,              # Controls the diversity of the generated text\n",
        "    top_k=50,                     # Keeps only the top-k most likely words\n",
        "    top_p=0.9,                    # Nucleus sampling (cumulative probability)\n",
        "    repetition_penalty=1.2,       # Penalty for repeating words or phrases\n",
        "    no_repeat_ngram_size=4,       # Prevents repetition of n-grams (e.g., bigrams)\n",
        "    do_sample=True,                # Enables sampling for greater diversity\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")[0]\n",
        "\n",
        "#Decode the generated token IDs to text\n",
        "completed_text = tokenizer.decode(output_text, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\n",
        "\n",
        "print(\"Input Text:\", input_text)\n",
        "print(\"Completed Text:\", completed_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sJ9l09G8CZR"
      },
      "outputs": [],
      "source": [
        "#Further training!\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Devive is: {device}\")\n",
        "\n",
        "# Load the  model\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(\"/content/drive/MyDrive/Study/extended_tokenizer_gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "finetuned_model = GPT2LMHeadModel.from_pretrained(\"/content/drive/MyDrive/Study/rus_gpt2_2_epoch\").to(device)\n",
        "\n",
        "# Dataset\n",
        "lm_dataset = load_from_disk('/content/drive/MyDrive/Study/lm_dataset')\n",
        "\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(\"/content/drive/MyDrive/Study/extended_tokenizer_gpt2\")\n",
        "# Model to CUDA\n",
        "model = GPT2LMHeadModel.from_pretrained(\"/content/drive/MyDrive/Study/rus_gpt2_2_epoch\").to(device)\n",
        "\n",
        "# Setting up training arguments\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/Study/rus_gpt2_3_epoch_dop/\",\n",
        "    overwrite_output_dir=True,\n",
        "    per_device_train_batch_size=128,\n",
        "    per_device_eval_batch_size=128,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=2000,\n",
        "    logging_steps=2000,\n",
        "    gradient_accumulation_steps=1,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.1,\n",
        "    warmup_steps=200,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    learning_rate=5e-3,\n",
        "    save_steps=10000,\n",
        "    save_total_limit=2,\n",
        "    #push_to_hub=True,\n",
        "    fp16=True,\n",
        "\n",
        ")\n",
        "\n",
        "#  Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=lm_dataset[\"train\"],\n",
        "    eval_dataset=lm_dataset[\"valid\"],\n",
        ")\n",
        "\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# Save\n",
        "trainer.save_model(\"/content/drive/MyDrive/Study/rus_gpt2_3_epoch_dop\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}